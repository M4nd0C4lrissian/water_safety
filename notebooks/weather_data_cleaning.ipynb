{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78900 entries, 0 to 78899\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Station Name            78900 non-null  object        \n",
      " 1   Date/Time               78900 non-null  datetime64[ns]\n",
      " 2   Max Temp (°C)           78072 non-null  float64       \n",
      " 3   Min Temp (°C)           78348 non-null  float64       \n",
      " 4   Mean Temp (°C)          77976 non-null  float64       \n",
      " 5   Heat Deg Days (°C)      77976 non-null  float64       \n",
      " 6   Cool Deg Days (°C)      77976 non-null  float64       \n",
      " 7   Total Rain (mm)         792 non-null    float64       \n",
      " 8   Total Precip (mm)       77076 non-null  float64       \n",
      " 9   Spd of Max Gust (km/h)  0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(8), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olimoon\\AppData\\Local\\Temp\\ipykernel_20656\\2323523089.py:7: DtypeWarning: Columns (20,22,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather_data = pd.read_csv(f\"..\\\\data\\\\raw\\\\weather_data\\\\climate_data\\\\daily\\\\{filename}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open .csv as a Dataframe\n",
    "filename = \"31688.csv\"\n",
    "weather_data = pd.read_csv(f\"..\\\\data\\\\raw\\\\weather_data\\\\climate_data\\\\daily\\\\{filename}\")\n",
    "\n",
    "# Select only relevant features\n",
    "# weather_data = weather_data.iloc[:, [2,4,5,6,7,9,11,13,15,17,19,23,29]]\n",
    "weather_data = weather_data.loc[ ['']]\n",
    "\n",
    "# Convert datetime str column to datetime object\n",
    "weather_data['Date/Time'] = pd.to_datetime(weather_data['Date/Time'])\n",
    "weather_data.drop(columns=[\"Year\", \"Month\", \"Day\"], axis=1, inplace=True)\n",
    "\n",
    "weather_data.info()\n",
    "# weather_data.tail\n",
    "\n",
    "# print(weather_data.loc[weather_data[\"Total Precip (mm)\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import only datetime and precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data: 6575 rows (72325 duplicates removed)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data while preserving raw strings\n",
    "weather = pd.read_csv(\n",
    "    \"../data/raw/weather_data/climate_data/daily/31688.csv\",\n",
    "    usecols=['Station Name', 'Date/Time', 'Total Precip (mm)'],\n",
    "    dtype={'Date/Time': str}  # Critical for accurate duplicate detection\n",
    ")\n",
    "\n",
    "# Step 1: Clean date strings (remove hidden characters/timezones)\n",
    "weather['Date/Time'] = (\n",
    "    weather['Date/Time']\n",
    "    .str.strip()  # Remove whitespace\n",
    "    .str[:10]     # Keep only YYYY-MM-DD (ignore time/timezone if present)\n",
    ")\n",
    "\n",
    "# Step 2: Remove TRUE duplicates (same station + same date)\n",
    "weather_clean = (\n",
    "    weather\n",
    "    .drop_duplicates(['Station Name', 'Date/Time'], keep='first')\n",
    "    .sort_values(['Station Name', 'Date/Time'])\n",
    ")\n",
    "\n",
    "# Step 3: Convert to datetime AFTER deduplication\n",
    "weather_clean['date'] = pd.to_datetime(weather_clean['Date/Time'], errors='coerce')\n",
    "\n",
    "# Final validation\n",
    "assert weather_clean.duplicated(['Station Name', 'date']).sum() == 0\n",
    "print(f\"Cleaned data: {len(weather_clean)} rows ({len(weather)-len(weather_clean)} duplicates removed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 true duplicates:\n",
      "Empty DataFrame\n",
      "Columns: [Station Name, Date/Time, Total Precip (mm), date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify TRUE duplicates (same station + same timestamp)\n",
    "dupes = weather_clean.duplicated(subset=['Station Name', 'Date/Time'], keep=False)\n",
    "print(f\"Found {dupes.sum()} true duplicates:\")\n",
    "print(weather_clean[dupes].sort_values(['Station Name', 'Date/Time']).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.dropna(subset=[\"Total Precip (mm)\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 77076 entries, 0 to 78899\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Station Name            77076 non-null  object        \n",
      " 1   Date/Time               77076 non-null  datetime64[ns]\n",
      " 2   Max Temp (°C)           77040 non-null  float64       \n",
      " 3   Min Temp (°C)           77064 non-null  float64       \n",
      " 4   Mean Temp (°C)          77040 non-null  float64       \n",
      " 5   Heat Deg Days (°C)      77040 non-null  float64       \n",
      " 6   Cool Deg Days (°C)      77040 non-null  float64       \n",
      " 7   Total Rain (mm)         792 non-null    float64       \n",
      " 8   Total Precip (mm)       77076 non-null  float64       \n",
      " 9   Spd of Max Gust (km/h)  0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(8), object(1)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toronto_city\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Get and format beach name\n",
    "stn_name = weather_data.iloc[0]['Station Name'] # Assuming only one beach name at a time \n",
    "stn_name = stn_name.lower().replace(\" \", \"_\")\n",
    "stn_name = re.sub(f'[^a-z0-9_]', \"\", stn_name)\n",
    "\n",
    "print(stn_name)\n",
    "# Write to file \n",
    "weather_data.to_parquet(f\"..\\\\data\\\\cleaned\\\\cleaned_{stn_name}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rainfall exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_precip = weather_data['Total Precip (mm)'] > 0 # 11892 entries in Toronto City\n",
    "weather_data.loc[has_precip]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot date vs. precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2008, 2025):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    mask = weather_data['Date/Time'].dt.year == i\n",
    "    plt.scatter(weather_data['Date/Time'].loc[mask], weather_data['Total Precip (mm)'].loc[mask])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Precipitation (mm)')\n",
    "    plt.title(f'{i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ecoli anomaly "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
